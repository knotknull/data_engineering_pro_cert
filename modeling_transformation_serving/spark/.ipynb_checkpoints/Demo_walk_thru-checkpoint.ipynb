{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "867ec043-acf0-4708-b337-44d48bd5e566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in /home/map/.local/lib/python3.10/site-packages (3.5.3)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /home/map/.local/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc480a22-0793-4e5f-9dc6-b803498704ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: findspark in /home/map/.local/lib/python3.10/site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "248b71ec-6f26-45fa-a07d-c15a1619fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c5215a5-f166-4cd0-a2e3-322429e766cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/15 11:06:48 WARN Utils: Your hostname, hexagon resolves to a loopback address: 127.0.1.1; using 192.168.99.98 instead (on interface wlx00c0cab05cdd)\n",
      "24/10/15 11:06:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/15 11:06:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark session first\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('example').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aabea3b5-5c35-4782-ae6f-95cc4022a43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.99.98:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>example</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb2857bffa0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6daa7d45-a818-4d23-846c-912f2cb7c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = spark.createDataFrame(\n",
    "    data = [(100, 1, 1, 50.1, 1, \"Thingamjig\", 5, \"Joe Reis\"),\n",
    "            (100, 2, 2, 25.08, 2, \"Whatchamacallit\", 5, \"Joe Reis\"),\n",
    "            (101, 1, 3, 75.23, 1, \"Whoozeewhatzit\", 7, \"Matt Housley\")],\n",
    "    schema = \"\"\" OrderID long, ItemNumber integer, SKU integer, Price double, Quantity integer, Name string, CustomerID long, CustomerName string\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85044c14-fee8-43d5-9098-c5b28c519350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---+-----+--------+---------------+----------+------------+\n",
      "|OrderID|ItemNumber|SKU|Price|Quantity|           Name|CustomerID|CustomerName|\n",
      "+-------+----------+---+-----+--------+---------------+----------+------------+\n",
      "|    100|         1|  1| 50.1|       1|     Thingamjig|         5|    Joe Reis|\n",
      "|    100|         2|  2|25.08|       2|Whatchamacallit|         5|    Joe Reis|\n",
      "|    101|         1|  3|75.23|       1| Whoozeewhatzit|         7|Matt Housley|\n",
      "+-------+----------+---+-----+--------+---------------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "860eeb7f-e03a-45fa-a09d-826b65c783c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets import a csv file into a dataframe,  still using the original spark object to do this:\n",
    "transactions_df = spark.read.csv('online_retail_map.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea4ace45-25bd-4260-b329-bbf5bb6656ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+--------+--------------+-----+-----------+--------------+\n",
      "|Invoice|StockCode|         Description|Quantity|   InvoiceDate|Price|Customer ID|       Country|\n",
      "+-------+---------+--------------------+--------+--------------+-----+-----------+--------------+\n",
      "| 489434|    85048|15CM CHRISTMAS GL...|      12|12/1/2009 7:45| 6.95|      13085|United Kingdom|\n",
      "| 489434|   79323P|  PINK CHERRY LIGHTS|      12|12/1/2009 7:45| 6.75|      13085|United Kingdom|\n",
      "| 489434|   79323W| WHITE CHERRY LIGHTS|      12|12/1/2009 7:45| 6.75|      13085|United Kingdom|\n",
      "| 489434|    22041|\"RECORD FRAME 7\"\"...|      48|12/1/2009 7:45|  2.1|      13085|United Kingdom|\n",
      "| 489434|    21232|STRAWBERRY CERAMI...|      24|12/1/2009 7:45| 1.25|      13085|United Kingdom|\n",
      "| 489434|    22064|PINK DOUGHNUT TRI...|      24|12/1/2009 7:45| 1.65|      13085|United Kingdom|\n",
      "+-------+---------+--------------------+--------+--------------+-----+-----------+--------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions_df.show(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01a80b9a-31b9-4ec6-b473-0b96f5f4a577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Invoice',\n",
       " 'StockCode',\n",
       " 'Description',\n",
       " 'Quantity',\n",
       " 'InvoiceDate',\n",
       " 'Price',\n",
       " 'Customer ID',\n",
       " 'Country']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the columns\n",
    "transactions_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "958fd16f-8ed9-4022-920d-9475b6fa143b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------+\n",
      "|Price|Quantity|       Country|\n",
      "+-----+--------+--------------+\n",
      "| 6.95|      12|United Kingdom|\n",
      "| 6.75|      12|United Kingdom|\n",
      "| 6.75|      12|United Kingdom|\n",
      "|  2.1|      48|United Kingdom|\n",
      "| 1.25|      24|United Kingdom|\n",
      "| 1.65|      24|United Kingdom|\n",
      "+-----+--------+--------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions_df.select('Price', 'Quantity', 'Country').show(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e5ed454-25e6-4417-bec2-ae90d6a86de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:==============>                                            (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------+\n",
      "|summary|             Price|          Quantity|    Country|\n",
      "+-------+------------------+------------------+-----------+\n",
      "|  count|           1067371|           1067371|    1067371|\n",
      "|   mean| 4.649387727415791|   9.9388984711033|       NULL|\n",
      "| stddev|123.55305872146302|172.70579407675285|       NULL|\n",
      "|    min|         -11062.06|                -1|  Australia|\n",
      "|    max|             99.96|               992|West Indies|\n",
      "+-------+------------------+------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# get summaries of columns\n",
    "transactions_df.select('Price', 'Quantity', 'Country').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b98b8bf-8a47-4160-94e7-59a6a239849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that is a calculation of two other columns\n",
    "transactions_df = transactions_df.withColumn(colName='Amount', col= transactions_df.Price * transactions_df.Quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22ce914d-52f8-4087-a2d5-bfd8373839dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+--------+--------------+-----+-----------+--------------+------------------+\n",
      "|Invoice|StockCode|         Description|Quantity|   InvoiceDate|Price|Customer ID|       Country|            Amount|\n",
      "+-------+---------+--------------------+--------+--------------+-----+-----------+--------------+------------------+\n",
      "| 489434|    85048|15CM CHRISTMAS GL...|      12|12/1/2009 7:45| 6.95|      13085|United Kingdom|              83.4|\n",
      "| 489434|   79323P|  PINK CHERRY LIGHTS|      12|12/1/2009 7:45| 6.75|      13085|United Kingdom|              81.0|\n",
      "| 489434|   79323W| WHITE CHERRY LIGHTS|      12|12/1/2009 7:45| 6.75|      13085|United Kingdom|              81.0|\n",
      "| 489434|    22041|\"RECORD FRAME 7\"\"...|      48|12/1/2009 7:45|  2.1|      13085|United Kingdom|100.80000000000001|\n",
      "| 489434|    21232|STRAWBERRY CERAMI...|      24|12/1/2009 7:45| 1.25|      13085|United Kingdom|              30.0|\n",
      "| 489434|    22064|PINK DOUGHNUT TRI...|      24|12/1/2009 7:45| 1.65|      13085|United Kingdom|39.599999999999994|\n",
      "+-------+---------+--------------------+--------+--------------+-----+-----------+--------------+------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions_df.show(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac7ed303-e593-475c-9c86-d05b69a917f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets rename an existing column name\n",
    "transactions_df = transactions_df.withColumnRenamed(existing='Invoice', new='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "993fcb67-acad-4fc3-9154-32557471271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets drop a column\n",
    "transactions_df = transactions_df.drop('Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaaac29f-9386-4652-9cb8-7e813174ec13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------------+-----+-----------+--------------+------------------+\n",
      "|    ID|StockCode|Quantity|   InvoiceDate|Price|Customer ID|       Country|            Amount|\n",
      "+------+---------+--------+--------------+-----+-----------+--------------+------------------+\n",
      "|489434|    85048|      12|12/1/2009 7:45| 6.95|      13085|United Kingdom|              83.4|\n",
      "|489434|   79323P|      12|12/1/2009 7:45| 6.75|      13085|United Kingdom|              81.0|\n",
      "|489434|   79323W|      12|12/1/2009 7:45| 6.75|      13085|United Kingdom|              81.0|\n",
      "|489434|    22041|      48|12/1/2009 7:45|  2.1|      13085|United Kingdom|100.80000000000001|\n",
      "|489434|    21232|      24|12/1/2009 7:45| 1.25|      13085|United Kingdom|              30.0|\n",
      "|489434|    22064|      24|12/1/2009 7:45| 1.65|      13085|United Kingdom|39.599999999999994|\n",
      "+------+---------+--------+--------------+-----+-----------+--------------+------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions_df.show(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50c2d0d9-6e35-4dbe-b5d3-48e6c2d2baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows with null values\n",
    "transactions_df = transactions_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24655639-a022-4e70-a98e-e3d21a60fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets filter rows \n",
    "transactions_df = transactions_df.filter(transactions_df.Quantity>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae282e85-9d92-469e-8dfa-44383cd0b7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------------+-----+-----------+--------------+------------------+\n",
      "|    ID|StockCode|Quantity|   InvoiceDate|Price|Customer ID|       Country|            Amount|\n",
      "+------+---------+--------+--------------+-----+-----------+--------------+------------------+\n",
      "|489434|    85048|      12|12/1/2009 7:45| 6.95|      13085|United Kingdom|              83.4|\n",
      "|489434|   79323P|      12|12/1/2009 7:45| 6.75|      13085|United Kingdom|              81.0|\n",
      "|489434|   79323W|      12|12/1/2009 7:45| 6.75|      13085|United Kingdom|              81.0|\n",
      "|489434|    22041|      48|12/1/2009 7:45|  2.1|      13085|United Kingdom|100.80000000000001|\n",
      "|489434|    21232|      24|12/1/2009 7:45| 1.25|      13085|United Kingdom|              30.0|\n",
      "|489434|    22064|      24|12/1/2009 7:45| 1.65|      13085|United Kingdom|39.599999999999994|\n",
      "+------+---------+--------+--------------+-----+-----------+--------------+------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions_df.show(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c64a7850-d54c-4126-80d3-b310fac40200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|    ID|       sum(Amount)|\n",
      "+------+------------------+\n",
      "|489677|             192.0|\n",
      "|491045|             303.2|\n",
      "|491658|155.05999999999997|\n",
      "|493542|            118.75|\n",
      "|493977|            275.95|\n",
      "|494244|            6711.0|\n",
      "|494277|           1335.92|\n",
      "|495185|           2507.06|\n",
      "|495783|             48.96|\n",
      "|496171|199.29999999999998|\n",
      "|496233|188.82999999999998|\n",
      "|496427|291.14000000000004|\n",
      "|497229| 312.5899999999999|\n",
      "|498070|207.15000000000006|\n",
      "|498125|190.95000000000005|\n",
      "|498328|            275.04|\n",
      "|500148|431.59000000000015|\n",
      "|500903|           2655.96|\n",
      "|500979|              11.9|\n",
      "|501046|             612.0|\n",
      "+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# calculate total amount spent on each order\n",
    "transactions_df.groupby(\"ID\").sum(\"Amount\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6b71802-5f76-46d4-b082-ec3270299083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+\n",
      "|        Country| count|\n",
      "+---------------+------+\n",
      "| United Kingdom|725296|\n",
      "|        Germany| 16703|\n",
      "|           EIRE| 15745|\n",
      "|         France| 13813|\n",
      "|    Netherlands|  5093|\n",
      "|          Spain|  3720|\n",
      "|        Belgium|  3069|\n",
      "|    Switzerland|  3012|\n",
      "|       Portugal|  2446|\n",
      "|      Australia|  1815|\n",
      "|Channel Islands|  1569|\n",
      "|          Italy|  1468|\n",
      "|         Norway|  1437|\n",
      "|         Sweden|  1319|\n",
      "|         Cyprus|  1155|\n",
      "|        Finland|  1032|\n",
      "|        Austria|   922|\n",
      "|        Denmark|   798|\n",
      "|         Greece|   657|\n",
      "|    Unspecified|   521|\n",
      "+---------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# total number of rows for each country in descending order\n",
    "transactions_df.groupby(\"Country\").count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa34d593-0f6d-454d-a872-9edf4cb044b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "@udf('string')\n",
    "def toUpper(word:str):\n",
    "    return word.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ae72086-6bb1-4905-af95-16e7b08a3ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+\n",
      "|    ID|toUpper(Country)|\n",
      "+------+----------------+\n",
      "|489434|  UNITED KINGDOM|\n",
      "|489434|  UNITED KINGDOM|\n",
      "|489434|  UNITED KINGDOM|\n",
      "|489434|  UNITED KINGDOM|\n",
      "|489434|  UNITED KINGDOM|\n",
      "|489434|  UNITED KINGDOM|\n",
      "+------+----------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## udf_to_upper = udf(toUpper, returnType='string')\n",
    "transactions_df.select('ID', toUpper('Country')).show(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "965a19fb-f00f-4f59-88dc-fd475acbf667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's replace an existing column in place with new values\n",
    "transactions_df = transactions_df.withColumn(colName='Country', \n",
    "                                             col=toUpper('Country'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f48c5c82-fe6e-493f-82ba-1ae757e08da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------------+-----+-----------+--------------+------------------+\n",
      "|    ID|StockCode|Quantity|   InvoiceDate|Price|Customer ID|       Country|            Amount|\n",
      "+------+---------+--------+--------------+-----+-----------+--------------+------------------+\n",
      "|489434|    85048|      12|12/1/2009 7:45| 6.95|      13085|UNITED KINGDOM|              83.4|\n",
      "|489434|   79323P|      12|12/1/2009 7:45| 6.75|      13085|UNITED KINGDOM|              81.0|\n",
      "|489434|   79323W|      12|12/1/2009 7:45| 6.75|      13085|UNITED KINGDOM|              81.0|\n",
      "|489434|    22041|      48|12/1/2009 7:45|  2.1|      13085|UNITED KINGDOM|100.80000000000001|\n",
      "|489434|    21232|      24|12/1/2009 7:45| 1.25|      13085|UNITED KINGDOM|              30.0|\n",
      "|489434|    22064|      24|12/1/2009 7:45| 1.65|      13085|UNITED KINGDOM|39.599999999999994|\n",
      "+------+---------+--------+--------------+-----+-----------+--------------+------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions_df.show(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6681c5d4-a551-4ffa-a8eb-3fbbb7aadb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.createOrReplaceTempView('orders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b600d48-cdd3-4107-9964-00f84d3e786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = spark.sql(\"\"\"\n",
    "SELECT ID, SUM(amount) as total\n",
    "from orders\n",
    "GROUP BY ID\n",
    "ORDER BY total DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26bf9a3d-ffc6-419b-ac1d-eae7167d44a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:=============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|    ID|             total|\n",
      "+------+------------------+\n",
      "|581483|          168469.6|\n",
      "|541431|           77183.6|\n",
      "|493819|44051.600000000006|\n",
      "|556444|           38970.0|\n",
      "|524181|33167.799999999996|\n",
      "|537659|31770.979999999996|\n",
      "+------+------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "total_df.show(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "615dedeb-5fc5-4895-b69c-6c929242bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toLower(word:str):\n",
    "    return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89e95847-9bd2-4d73-b216-5a9b9100c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = spark.udf.register(\"udf_to_lower\", toLower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be214acc-6f0d-45de-9abc-e34706a3d168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|udf_to_lower(country)|\n",
      "+---------------------+\n",
      "|              finland|\n",
      "|            australia|\n",
      "|               greece|\n",
      "|             portugal|\n",
      "|              nigeria|\n",
      "|               poland|\n",
      "|              austria|\n",
      "|                malta|\n",
      "|                japan|\n",
      "|          switzerland|\n",
      "|               sweden|\n",
      "|          netherlands|\n",
      "| united arab emirates|\n",
      "|                 eire|\n",
      "|               france|\n",
      "|          unspecified|\n",
      "|       united kingdom|\n",
      "|              germany|\n",
      "|                  rsa|\n",
      "|                italy|\n",
      "+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT DISTINCT udf_to_lower(country)\n",
    "FROM orders\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e182f852-61b2-4b32-b30a-585c93470d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_category_df = spark.createDataFrame(\n",
    "    data = [(22423, 'category_a'), (21212, 'category_b'), \n",
    "            (21232, 'category_c'), (84879, 'category_a')],\n",
    "    schema = 'itemID string, category string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b85aceb6-63d7-4069-b097-12692bbc2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_category_df.createTempView('items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d619ff2b-f6a4-4325-97bb-050af68df013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|  category|       avg(amount)|\n",
      "+----------+------------------+\n",
      "|category_c|20.994959999999978|\n",
      "|category_a| 66.62807636539425|\n",
      "|category_b|16.604122079879243|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT category, AVG(amount)\n",
    "from items\n",
    "LEFT JOIN orders ON items.itemID = orders.stockcode\n",
    "GROUP by category\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49328246-8a84-4a49-a553-a35f8e387b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
